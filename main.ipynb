{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Required Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "# Function to install a package using pip\n",
    "def install_package(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# List of required packages\n",
    "required_packages = [\n",
    "    \"scikit-learn\",\n",
    "    \"scikit-image\",\n",
    "    \"numpy\",\n",
    "    \"matplotlib\",\n",
    "    \"opencv-python\",\n",
    "    \"roboflow\",\n",
    "    \"pandas\",\n",
    "]\n",
    "\n",
    "# Check and install each package\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        __import__(package)\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        install_package(package)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of HOG Feature Descriptor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of HOG Feature Descriptor involves the following steps:\n",
    "1. Preprocess the data\n",
    "2. Calculate and Visualize the Histogram of Gradients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread, imshow\n",
    "# from skimage.transform import resize\n",
    "import skimage\n",
    "from skimage.color import rgb2gray\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import cv2\n",
    "\n",
    "image_BGR = cv2.imread(\"./media/puppy.jpg\")\n",
    "image_RGB = cv2.cvtColor(image_BGR, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "gray_image = cv2.cvtColor(image_BGR, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "resized_image = cv2.resize(image_RGB, (64, 128))\n",
    "resized_gray_image = cv2.resize(gray_image, (64, 128))\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "axes[0, 0].imshow(image_RGB)\n",
    "axes[0, 1].imshow(resized_image)\n",
    "axes[1, 0].imshow(gray_image, cmap='gray')\n",
    "axes[1, 1].imshow(resized_gray_image, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Calculate and Visualize the Histogram of Gradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "\n",
    "import cv2\n",
    "\n",
    "fd, hog_image = hog(resized_gray_image, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(8, 4), sharex=True, sharey=True)\n",
    "\n",
    "ax1.imshow(resized_image)\n",
    "ax1.set_title('Input image')\n",
    "\n",
    "ax2.imshow(resized_gray_image, cmap=plt.cm.gray)\n",
    "ax2.set_title('Grayscale image') \n",
    "\n",
    "ax3.imshow(hog_image, cmap=plt.cm.gray)\n",
    "ax3.set_title('Histogram of Oriented Gradients') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of eXtended Center-Symmetric Local Binary Pattern (XCS-LBP) Feature Descriptor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Calculate XCS-LBP operator applied to the whole grayscale image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_BGR = cv2.imread(\"./media/test_image.png\")\n",
    "image_RGB = cv2.cvtColor(image_BGR, cv2.COLOR_BGR2RGB)\n",
    "gray_image = cv2.cvtColor(image_RGB, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "def valid_index(image, x, y):\n",
    "    return (x >= 0 and y >= 0 and x < image.shape[0] and y < image.shape[1])\n",
    "\n",
    "def threshold_function(x):\n",
    "    return 1 if x >= 0 else 0\n",
    "\n",
    "def calculate_xcs_lbp_value(x, y, image, neighborhood_size=8):\n",
    "    result = 0\n",
    "    mask = [(-1, -1), (-1, 0), (-1, 1), (0, 1), (1, 1), (1, 0), (1, -1), (0, -1)]\n",
    "    half_neighborhood_size = int(neighborhood_size/2)\n",
    "    image=image.astype('float32')\n",
    "    for i in range(half_neighborhood_size):\n",
    "        index1 = (x+mask[i][0], y+mask[i][1])\n",
    "        index2 = (x+mask[i+half_neighborhood_size][0], y+mask[i+half_neighborhood_size][1])\n",
    "        value1 = image[index1[0], index1[1]] if valid_index(image, index1[0], index1[1]) else 0\n",
    "        value2 = image[index2[0], index2[1]] if valid_index(image, index2[0], index2[1]) else 0\n",
    "\n",
    "        g1 = (value1-value2) + image[x, y]\n",
    "        g2 = (value1-image[x, y])*(value2-image[x, y])\n",
    "        power_val = [1, 2, 4, 8, 16, 32, 64, 128]\n",
    "        result += (threshold_function(g1+g2)*power_val[i])\n",
    "    return result\n",
    "\n",
    "xcs_lbp_image = gray_image.copy()\n",
    "for i in range(xcs_lbp_image.shape[0]):\n",
    "    for j in range(xcs_lbp_image.shape[1]):\n",
    "        xcs_lbp_image[i, j] = calculate_xcs_lbp_value(i, j, gray_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12,8))\n",
    "ax1.imshow(image_RGB)\n",
    "ax1.set_title(\"Input Image\")\n",
    "ax2.imshow(gray_image, cmap='gray')\n",
    "ax2.set_title(\"Grayscale Image\")\n",
    "ax3.imshow(xcs_lbp_image, cmap='gray')\n",
    "ax3.set_title(\"XCS-LBP\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset_folder = \"./INRIA_Person_detection_dataset\"\n",
    "dataset_name_list = [\"train\", \"test\", \"valid\"]\n",
    "data_folder = \"./data\"\n",
    "\n",
    "X = {}\n",
    "y = {}\n",
    "\n",
    "for dataset_name in dataset_name_list:\n",
    "    if not(os.path.exists(data_folder)):\n",
    "        os.mkdir(data_folder)\n",
    "    features_path = os.path.join(data_folder, \"extracted_features\")\n",
    "    if not(os.path.exists(features_path)):\n",
    "        os.mkdir(features_path)\n",
    "    features_path = os.path.join(features_path, dataset_name)\n",
    "    if not(os.path.exists(features_path)):\n",
    "        os.mkdir(features_path)\n",
    "    labeled_data_path = os.path.join(features_path, \"HOG_features.npy\")\n",
    "    if not(os.path.exists(labeled_data_path)):\n",
    "        dataset_path = os.path.join(dataset_folder, dataset_name)\n",
    "        annotations_path = os.path.join(dataset_path, \"_annotations.csv\")\n",
    "        annotations = pd.read_csv(annotations_path)\n",
    "        pair_list = []\n",
    "        hog_image_list = []\n",
    "        for index, row in annotations.iterrows():\n",
    "            input_image = cv2.imread(os.path.join(dataset_path, row[\"filename\"]))\n",
    "            grayscale_input_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)\n",
    "            cropped_image = grayscale_input_image[row[\"ymin\"]: row[\"ymax\"], row[\"xmin\"]: row[\"xmax\"]]\n",
    "            cropped_image = cv2.resize(cropped_image, (64, 128))\n",
    "\n",
    "            features, hog_image = hog(cropped_image, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True)\n",
    "            pair_list.append((features, 1 if row[\"class\"]==\"person\" else 0))\n",
    "            hog_image_list.append((hog_image, 1 if row[\"class\"]==\"person\" else 0))\n",
    "\n",
    "        np.save(os.path.join(features_path, \"HOG_features\"), np.asarray(pair_list, dtype=\"object\"))\n",
    "        np.save(os.path.join(features_path, \"HOG_images\"), np.asarray(hog_image_list, dtype=\"object\"))\n",
    "    \n",
    "    labeled_data = np.load(labeled_data_path, allow_pickle=True)\n",
    "    X[dataset_name] = [pair[0] for pair in labeled_data]\n",
    "    y[dataset_name] = [pair[1] for pair in labeled_data] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "rf = RandomForestClassifier(n_estimators=100, criterion=\"gini\", max_features=\"sqrt\", random_state=42)\n",
    "rf.fit(X[\"train\"], y[\"train\"])\n",
    "\n",
    "test_report = classification_report(y[\"test\"], rf.predict(X[\"test\"]))\n",
    "print(test_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "model = svm.SVC(kernel='linear')\n",
    "model.fit(X[\"train\"], y[\"train\"])\n",
    "\n",
    "test_report = classification_report(y[\"test\"], model.predict(X[\"test\"]))\n",
    "print(test_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = \"./INRIA_Person_detection_dataset\"\n",
    "dataset_name_list = [\"train\", \"test\", \"valid\"]\n",
    "data_folder = \"./data\"\n",
    "\n",
    "X = {}\n",
    "y = {}\n",
    "A = {}\n",
    "b = {}\n",
    "\n",
    "for dataset_name in dataset_name_list:\n",
    "    if not(os.path.exists(data_folder)):\n",
    "        os.mkdir(data_folder)\n",
    "    features_path = os.path.join(data_folder, \"extracted_features\")\n",
    "    if not(os.path.exists(features_path)):\n",
    "        os.mkdir(features_path)\n",
    "    features_path = os.path.join(features_path, dataset_name)\n",
    "    if not(os.path.exists(features_path)):\n",
    "        os.mkdir(features_path)\n",
    "    labeled_data_path = os.path.join(features_path, \"XCS_LBP_features.npy\")\n",
    "    if not(os.path.exists(labeled_data_path)):\n",
    "        dataset_path = os.path.join(dataset_folder, dataset_name)\n",
    "        annotations_path = os.path.join(dataset_path, \"_annotations.csv\")\n",
    "        annotations = pd.read_csv(annotations_path)\n",
    "        pair_list = []\n",
    "        xcs_lbp_image_list = []\n",
    "        for index, row in annotations.iterrows():\n",
    "            input_image = cv2.imread(os.path.join(dataset_path, row[\"filename\"]))\n",
    "            grayscale_input_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)\n",
    "            cropped_image = grayscale_input_image[row[\"ymin\"]: row[\"ymax\"], row[\"xmin\"]: row[\"xmax\"]]\n",
    "            cropped_image = cv2.resize(cropped_image, (128, 256))\n",
    "            xcs_lbp_image = cropped_image.copy()\n",
    "\n",
    "            for i in range(xcs_lbp_image.shape[0]):\n",
    "                for j in range(xcs_lbp_image.shape[1]):\n",
    "                    xcs_lbp_image[i, j] = calculate_xcs_lbp_value(i, j, cropped_image)\n",
    "\n",
    "            features = []\n",
    "            for i in range(xcs_lbp_image.shape[0]):\n",
    "                features.extend(xcs_lbp_image[i])\n",
    "\n",
    "            pair_list.append((features, 1 if row[\"class\"]==\"person\" else 0))\n",
    "            xcs_lbp_image_list.append((xcs_lbp_image, 1 if row[\"class\"]==\"person\" else 0))\n",
    "\n",
    "        np.save(os.path.join(features_path, \"XCS_LBP_features\"), np.asarray(pair_list, dtype=\"object\"))\n",
    "        np.save(os.path.join(features_path, \"XCS_LBP_images\"), np.asarray(xcs_lbp_image_list, dtype=\"object\"))\n",
    "    \n",
    "    labeled_data = np.load(labeled_data_path, allow_pickle=True)\n",
    "    X[dataset_name] = [pair[0] for pair in labeled_data]\n",
    "    y[dataset_name] = [pair[1] for pair in labeled_data] \n",
    "\n",
    "    visualized_data_path = os.path.join(features_path, \"XCS_LBP_images.npy\")\n",
    "    visualized_data = np.load(visualized_data_path, allow_pickle=True)\n",
    "    \n",
    "    A[dataset_name] = [pair[0] for pair in visualized_data]\n",
    "    b[dataset_name] = [pair[1] for pair in visualized_data] \n",
    "\n",
    "\n",
    "dataset_path = os.path.join(dataset_folder, \"valid\")\n",
    "annotations_path = os.path.join(dataset_path, \"_annotations.csv\")\n",
    "annotations = pd.read_csv(annotations_path)\n",
    "for index, row in annotations.iterrows():\n",
    "    if index == 201:\n",
    "        input_image = cv2.imread(os.path.join(dataset_path, row[\"filename\"]))\n",
    "        grayscale_input_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)\n",
    "        cropped_image = grayscale_input_image[row[\"ymin\"]: row[\"ymax\"], row[\"xmin\"]: row[\"xmax\"]]\n",
    "\n",
    "        xcs_lbp_image = cropped_image.copy()\n",
    "\n",
    "        for i in range(xcs_lbp_image.shape[0]):\n",
    "            for j in range(xcs_lbp_image.shape[1]):\n",
    "                xcs_lbp_image[i, j] = calculate_xcs_lbp_value(i, j, cropped_image)\n",
    "        test_image = cropped_image\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,8))\n",
    "        ax1.imshow(test_image, cmap='gray')\n",
    "        ax1.set_title(\"Input Image\")\n",
    "        ax2.imshow(A[\"valid\"][index], cmap='gray')\n",
    "        ax2.set_title(\"XCS-LBP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "rf = RandomForestClassifier(n_estimators=100, criterion=\"entropy\", max_features=\"log2\", random_state=42)\n",
    "rf.fit(X[\"train\"], y[\"train\"])\n",
    "\n",
    "test_report = classification_report(y[\"test\"], rf.predict(X[\"test\"]))\n",
    "print(test_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = svm.SVC(kernel='linear')\n",
    "model.fit(X[\"train\"], y[\"train\"])\n",
    "\n",
    "test_report = classification_report(y[\"test\"], model.predict(X[\"test\"]))\n",
    "print(test_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
